# ML Model Drift Detection & Performance Monitoring System

ğŸš€ Production-style ML monitoring system with Streamlit dashboard and Evidently AI integration.

## ğŸ” Overview
This project simulates a production ML monitoring system that detects data drift, prediction drift, and model performance degradation on new incoming datasets.


The system compares new data distributions against baseline training statistics and flags potential risks to model reliability.

---

## âœ¨ Features

- Detects **Feature Drift** using baseline statistics
- Detects **Prediction Drift** using prediction distribution comparison
- Detects **Target Drift & Model Performance Drift** using Evidently AI
- Interactive **Streamlit Dashboard**
- Supports **real-time CSV upload**
- Shows **visual HTML reports** for detailed drift analysis
- Provides **Model Health Status** (STABLE / MONITOR / HIGH RISK)

---

## ğŸ“¸ Dashboard Preview

### Baseline Statistics Drift Detection
![Baseline Drift](reports/screenshots/baseline.png)

### Evidently AI Data Drift Report
![Evidently Drift](reports/screenshots/evidently.png)

---

## âš™ï¸ Tech Stack
- Python
- Scikit-learn
- Pandas
- NumPy
- Streamlit
- Joblib
- Evidently AI

---

## Project Architecture
```text 
User Upload CSV
      â†“
Load Saved Pipeline
      â†“
Generate Predictions
      â†“
Drift Detection
  â”œâ”€ Baseline Math
  â””â”€ Evidently AI
      â†“
Streamlit Dashboard

```
---

## ğŸ§  Key Concepts Implemented
- Feature Drift Detection (mean shift vs baseline standard deviation)
- Prediction Drift Detection (positive-rate distribution change)
- ML Pipeline with ColumnTransformer
- Baseline statistics persistence
- Model health status classification (STABLE / MONITOR / HIGH RISK)

---

## ğŸš€ How It Works
1. Train the ML model and save:
   - Model pipeline
   - Baseline feature statistics
   - Baseline prediction distribution
2. Upload a new dataset via Streamlit
3. System computes:
   - Feature-level drift
   - Prediction drift
4. Model health status is reported as:
   - **STABLE**
   - **MONITOR**
   - **HIGH RISK**

---

## ğŸ“¦ Saved Artifacts

The system saves the following artifacts after training:

- model_pipeline.pkl â†’ trained ML pipeline
- baseline_stats.pkl â†’ baseline feature statistics
- baseline_positive_rate.pkl â†’ baseline prediction distribution

These are used for real-time drift comparison.

---


## Project Structure
```text

ML-DATA-DRIFT-MONITORING-PROJECT/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ readme.md
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ model_pipeline.pkl
â”‚   â”œâ”€â”€ baseline_stats.pkl
â”‚   â””â”€â”€ baseline_positive_rate.pkl
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ baseline_statistics.py
â”‚   â”œâ”€â”€ drift_utils.py
â”‚   â”œâ”€â”€ model_utils.py
â”‚   â””â”€â”€ evidently_reports.py
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ data_drift.html
â”‚   â”œâ”€â”€ target_drift.html
â”‚   â””â”€â”€ classification_drift.html
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Telco_Customer_churn.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ model_training.ipynb

```
---

## â–¶ï¸ Run the Application
```bash
pip install -r requirements.txt
streamlit run app.py
```
---

## ğŸ“‹ Requirements

Python 3.11
Streamlit
Scikit-learn
Pandas
NumPy
Evidently AI
Joblib

---